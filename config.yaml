# LLM Adapter Configuration
# Environment variables can be referenced using ${VAR_NAME} syntax

llm:
  default_provider: dashscope

providers:
  openai:
    api_key: 
    base_url: https://api.openai.com
    models:
      cheap: gpt-4o-mini
      normal: gpt-4o
      premium: gpt-4-turbo

  gemini:
    api_key: REDACTED_GOOGLE_API_KEY
    models:
      cheap: gemini-2.5-flash
      normal: gemini-2.5-flash
      premium: gemini-2.5-flash

  # cloudflare:
  #   api_key: 
  #   account_id: ${CF_ACCOUNT_ID}
  #   models:
  #     cheap: "@cf/meta/llama-3-8b-instruct"
  #     normal: "@cf/meta/llama-3-8b-instruct"

  huggingface:
    api_key: 
    default_model: meta-llama/Llama-3.1-8B-Instruct
    models:
      cheap: meta-llama/Llama-3.1-8B-Instruct
      normal: meta-llama/Llama-3.1-8B-Instruct

  dashscope:
    api_key: REDACTED_TOKEN
    base_url: https://dashscope.aliyuncs.com/api/v1
    models:
      cheap: qwen-flash
      normal: qwen-flash
      premium: qwen-flash

  openrouter:
    api_key: 
    base_url: https://openrouter.ai/api/v1
    models:
      cheap: meta-llama/llama-3.1-8b-instruct
      normal: anthropic/claude-3.5-sonnet
      premium: anthropic/claude-3-opus

pricing:
  openai:
    gpt-4o-mini:
      input_cost_per_1m: 0.15
      output_cost_per_1m: 0.60
    gpt-4o:
      input_cost_per_1m: 2.50
      output_cost_per_1m: 10.00
    gpt-4-turbo:
      input_cost_per_1m: 10.00
      output_cost_per_1m: 30.00

  gemini:
    gemini-1.5-flash:
      input_cost_per_1m: 0.075
      output_cost_per_1m: 0.30
    gemini-1.5-pro:
      input_cost_per_1m: 1.25
      output_cost_per_1m: 5.00

  cloudflare:
    "@cf/meta/llama-3-8b-instruct":
      input_cost_per_1m: 0.00
      output_cost_per_1m: 0.00

  huggingface:
    meta-llama/Llama-3.1-8B-Instruct:
      input_cost_per_1m: 0.00
      output_cost_per_1m: 0.00

  dashscope:
    qwen-turbo:
      input_cost_per_1m: 0.30
      output_cost_per_1m: 0.60
    qwen-plus:
      input_cost_per_1m: 0.80
      output_cost_per_1m: 2.00
    qwen-max:
      input_cost_per_1m: 2.00
      output_cost_per_1m: 6.00

  openrouter:
    meta-llama/llama-3.1-8b-instruct:
      input_cost_per_1m: 0.055
      output_cost_per_1m: 0.055
    anthropic/claude-3.5-sonnet:
      input_cost_per_1m: 3.00
      output_cost_per_1m: 15.00
    anthropic/claude-3-opus:
      input_cost_per_1m: 15.00
      output_cost_per_1m: 75.00

profile:
  trait_rules:
    min_confidence_to_count: 0.7
